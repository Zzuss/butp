import { NextRequest, NextResponse } from 'next/server'
import { writeFile, readdir, stat, mkdir } from 'fs/promises'
import { join, extname } from 'path'
import { existsSync, mkdirSync } from 'fs'
import { spawn } from 'child_process'

interface BatchFileInfo {
  id: string
  filename: string
  year: string
  filePath: string
  tempDir: string
}

interface BatchPredictionResult {
  batchId: string
  totalFiles: number
  results: { [fileId: string]: any }
  errors: { [fileId: string]: string }
  startTime: number
  endTime?: number
}

// å¹´çº§é…ç½®ï¼ˆå¤ç”¨ç°æœ‰é…ç½®ï¼‰
const YEAR_CONFIGS: { [key: string]: any } = {
  '2021': {
    year: '2021',
    majors: {
      'ç‰©è”ç½‘å·¥ç¨‹': '2021çº§ç‰©è”ç½‘å·¥ç¨‹åŸ¹å…»æ–¹æ¡ˆ.xlsx',
      'ç”µä¿¡å·¥ç¨‹åŠç®¡ç†': '2021çº§ç”µä¿¡å·¥ç¨‹åŠç®¡ç†åŸ¹å…»æ–¹æ¡ˆ.xlsx',
      'ç”µå­å•†åŠ¡åŠæ³•å¾‹': '2021çº§ç”µå­å•†åŠ¡åŠæ³•å¾‹åŸ¹å…»æ–¹æ¡ˆ.xlsx'
    }
  },
  '2022': {
    year: '2022',
    majors: {
      'æ™ºèƒ½ç§‘å­¦ä¸æŠ€æœ¯': '2022çº§æ™ºèƒ½ç§‘å­¦ä¸æŠ€æœ¯åŸ¹å…»æ–¹æ¡ˆ.xlsx',
      'ç‰©è”ç½‘å·¥ç¨‹': '2022çº§ç‰©è”ç½‘å·¥ç¨‹åŸ¹å…»æ–¹æ¡ˆ.xlsx',
      'ç”µä¿¡å·¥ç¨‹åŠç®¡ç†': '2022çº§ç”µä¿¡å·¥ç¨‹åŠç®¡ç†åŸ¹å…»æ–¹æ¡ˆ.xlsx',
      'ç”µå­ä¿¡æ¯å·¥ç¨‹': '2022çº§ç”µå­ä¿¡æ¯å·¥ç¨‹åŸ¹å…»æ–¹æ¡ˆ.xlsx'
    }
  },
  '2023': {
    year: '2023',
    majors: {
      'æ™ºèƒ½ç§‘å­¦ä¸æŠ€æœ¯': '2023çº§æ™ºèƒ½ç§‘å­¦ä¸æŠ€æœ¯åŸ¹å…»æ–¹æ¡ˆ.xlsx',
      'ç‰©è”ç½‘å·¥ç¨‹': '2023çº§ç‰©è”ç½‘å·¥ç¨‹åŸ¹å…»æ–¹æ¡ˆ.xlsx',
      'ç”µä¿¡å·¥ç¨‹åŠç®¡ç†': '2023çº§ç”µä¿¡å·¥ç¨‹åŠç®¡ç†åŸ¹å…»æ–¹æ¡ˆ.xlsx',
      'ç”µå­ä¿¡æ¯å·¥ç¨‹': '2023çº§ç”µå­ä¿¡æ¯å·¥ç¨‹åŸ¹å…»æ–¹æ¡ˆ.xlsx'
    }
  },
  '2024': {
    year: '2024',
    majors: {
      'æ™ºèƒ½ç§‘å­¦ä¸æŠ€æœ¯': '2024çº§æ™ºèƒ½ç§‘å­¦ä¸æŠ€æœ¯åŸ¹å…»æ–¹æ¡ˆ.xlsx',
      'ç‰©è”ç½‘å·¥ç¨‹': '2024çº§ç‰©è”ç½‘å·¥ç¨‹åŸ¹å…»æ–¹æ¡ˆ.xlsx',
      'ç”µä¿¡å·¥ç¨‹åŠç®¡ç†': '2024çº§ç”µä¿¡å·¥ç¨‹åŠç®¡ç†åŸ¹å…»æ–¹æ¡ˆ.xlsx',
      'ç”µå­ä¿¡æ¯å·¥ç¨‹': '2024çº§ç”µå­ä¿¡æ¯å·¥ç¨‹åŸ¹å…»æ–¹æ¡ˆ.xlsx'
    }
  }
}

// ä¸“ä¸šä»£ç æ˜ å°„
const MAJOR_CODE_MAP: { [key: string]: string } = {
  'æ™ºèƒ½ç§‘å­¦ä¸æŠ€æœ¯': 'ai',
  'ç”µå­ä¿¡æ¯å·¥ç¨‹': 'ee',
  'ç‰©è”ç½‘å·¥ç¨‹': 'iot',
  'ç”µä¿¡å·¥ç¨‹åŠç®¡ç†': 'tewm'
}

// æ‰¹é‡å¯¼å…¥æˆç»©æ•°æ®ï¼ˆé¿å…å†²çªï¼‰
async function batchImportAcademicResults(files: BatchFileInfo[]) {
  try {
    console.log(`å¼€å§‹æ‰¹é‡å¯¼å…¥ ${files.length} ä¸ªæ–‡ä»¶çš„æˆç»©æ•°æ®`)
    
    const supabaseUrl = 'https://sdtarodxdvkeeiaouddo.supabase.co'
    const supabaseAnonKey = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNkdGFyb2R4ZHZrZWVpYW91ZGRvIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTExMjUxNDksImV4cCI6MjA2NjcwMTE0OX0.4aY7qvQ6uaEfa5KK4CEr2s8BvvmX55g7FcefvhsGLTM'
    
    const { createClient } = require('@supabase/supabase-js')
    const supabase = createClient(supabaseUrl, supabaseAnonKey)
    const XLSX = require('xlsx')
    
    // åˆå¹¶æ‰€æœ‰æ–‡ä»¶çš„æ•°æ®ï¼Œæ·»åŠ æ–‡ä»¶æ ‡è¯†ç¬¦é¿å…å†²çª
    const allData: any[] = []
    const fileResults: { [fileId: string]: any } = {}
    
    for (const fileInfo of files) {
      try {
        console.log(`è¯»å–æ–‡ä»¶: ${fileInfo.filename}`)
        
        // è¯»å–Excelæ–‡ä»¶
        let workbook: any
        try {
          workbook = XLSX.readFile(fileInfo.filePath)
        } catch (error) {
          // å°è¯•ç¼“å†²è¯»å–
          const fs = require('fs')
          const buffer = fs.readFileSync(fileInfo.filePath)
          workbook = XLSX.read(buffer, { type: 'buffer' })
        }
        
        const sheetName = workbook.SheetNames[0]
        const worksheet = workbook.Sheets[sheetName]
        
        if (!worksheet) {
          throw new Error('Excelæ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°å·¥ä½œè¡¨')
        }
        
        const jsonData = XLSX.utils.sheet_to_json(worksheet)
        console.log(`æ–‡ä»¶ ${fileInfo.filename} è¯»å–åˆ° ${jsonData.length} æ¡è®°å½•`)
        
        // å¤„ç†æ•°æ®ï¼Œæ·»åŠ æ‰¹æ¬¡æ ‡è¯†ç¬¦
        const processedData = jsonData.map((row: any) => ({
          SNH: row.SNH || null,
          Semester_Offered: row.Semester_Offered || null,
          Current_Major: row.Current_Major || null,
          Course_ID: row.Course_ID || null,
          Course_Name: row.Course_Name || null,
          Grade: row.Grade ? String(row.Grade) : null,
          Grade_Remark: row.Grade_Remark || null,
          Course_Type: row.Course_Type || null,
          Course_Attribute: row['Course_Attribute '] || row.Course_Attribute || null,
          Hours: row.Hours ? String(row.Hours) : null,
          Credit: row.Credit ? String(row.Credit) : null,
          Offering_Unit: row.Offering_Unit || null,
          Tags: row.Tags || null,
          Description: row.Description || null,
          Exam_Type: row.Exam_Type || null,
          Assessment_Method: row['Assessment_Method '] || row.Assessment_Method || null,
          year: parseInt(fileInfo.year),
          batch_file_id: fileInfo.id // æ·»åŠ æ‰¹æ¬¡æ ‡è¯†ç¬¦
        }))
        
        allData.push(...processedData)
        fileResults[fileInfo.id] = {
          recordCount: processedData.length,
          success: true
        }
        
      } catch (error) {
        console.error(`å¤„ç†æ–‡ä»¶ ${fileInfo.filename} å¤±è´¥:`, error)
        fileResults[fileInfo.id] = {
          recordCount: 0,
          success: false,
          error: error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'
        }
      }
    }
    
    // å…ˆæ¸…ç©ºå¯¹åº”å¹´çº§çš„æ•°æ®
    const years = [...new Set(files.map(f => f.year))]
    for (const year of years) {
      console.log(`æ¸…ç©º ${year} çº§çš„ç°æœ‰æ•°æ®...`)
      const { error: deleteError } = await supabase
        .from('academic_results')
        .delete()
        .eq('year', parseInt(year))
      
      if (deleteError) {
        console.error(`æ¸…ç©º ${year} çº§æ•°æ®å¤±è´¥:`, deleteError)
      }
    }
    
    // æ‰¹é‡æ’å…¥æ•°æ®
    if (allData.length > 0) {
      console.log(`å¼€å§‹æ‰¹é‡æ’å…¥ ${allData.length} æ¡è®°å½•åˆ°æ•°æ®åº“`)
      
      const batchSize = 1000
      let totalInserted = 0
      
      for (let i = 0; i < allData.length; i += batchSize) {
        const batch = allData.slice(i, i + batchSize)
        
        try {
          const { error } = await supabase
            .from('academic_results')
            .insert(batch)
          
          if (error) {
            throw error
          }
          
          totalInserted += batch.length
          console.log(`æ‰¹é‡æ’å…¥è¿›åº¦: ${totalInserted}/${allData.length}`)
          
        } catch (error) {
          console.error(`æ‰¹é‡æ’å…¥å¤±è´¥:`, error)
          throw error
        }
      }
      
      console.log(`âœ… æ‰¹é‡å¯¼å…¥å®Œæˆ: ${totalInserted} æ¡è®°å½•`)
    }
    
    return {
      success: true,
      totalRecords: allData.length,
      fileResults
    }
    
  } catch (error) {
    console.error('æ‰¹é‡å¯¼å…¥å¤±è´¥:', error)
    throw error
  }
}

// è¿è¡Œå•ä¸ªæ–‡ä»¶çš„é¢„æµ‹
async function runSinglePrediction(fileInfo: BatchFileInfo): Promise<any> {
  return new Promise((resolve) => {
    const functionDir = join(process.cwd(), 'function')
    const modelDir = join(functionDir, 'Model_Params', 'Task3_CatBoost_Model')
    const planDir = join(functionDir, `education-plan${fileInfo.year}`)
    
    console.log(`å¼€å§‹å¤„ç†æ–‡ä»¶: ${fileInfo.filename} (${fileInfo.year}çº§)`)
    
    // åˆ›å»ºPythonè„šæœ¬
    const pythonScript = `
import sys
import os
function_dir = r"${functionDir}"
sys.path.insert(0, function_dir)

try:
    import pandas as pd
    import numpy as np
    from catboost import CatBoostClassifier
    from sklearn.preprocessing import StandardScaler
    import openpyxl
    print("âœ“ ä¾èµ–åŒ…åŠ è½½å®Œæˆ")
except ImportError as e:
    print(f"âœ— ä¾èµ–åŒ…å¯¼å…¥é”™è¯¯: {e}")
    sys.exit(1)

os.chdir(function_dir)
try:
    import Optimization_model_func3_1 as opt
    print("âœ“ é¢„æµ‹æ¨¡å—åŠ è½½å®Œæˆ")
except ImportError as e:
    print(f"âœ— é¢„æµ‹æ¨¡å—åŠ è½½å¤±è´¥: {e}")
    sys.exit(1)

def main():
    base_dir = r"${functionDir}"
    scores_file = r"${fileInfo.filePath}"
    temp_dir = r"${fileInfo.tempDir}"
    year = "${fileInfo.year}"
    
    print(f"=== å¼€å§‹ {year} çº§æ–‡ä»¶ ${fileInfo.filename} é¢„æµ‹ ===")
    
    majors_config = ${JSON.stringify(YEAR_CONFIGS[fileInfo.year].majors)}
    plan_dir = os.path.join(base_dir, f"education-plan{year}")
    
    per_major_files = {}
    total_students = 0
    
    for major_name, plan_filename in majors_config.items():
        course_file = os.path.join(plan_dir, plan_filename)
        if not os.path.exists(course_file):
            print(f"è­¦å‘Š: åŸ¹å…»æ–¹æ¡ˆæ–‡ä»¶ä¸å­˜åœ¨: {course_file}")
            continue
        
        out_file = os.path.join(temp_dir, f"${fileInfo.id}_Cohort{year}_Predictions_{opt.get_major_code(major_name)}.xlsx")
        
        print(f"æ­£åœ¨å¤„ç† {major_name}...")
        
        try:
            pred_df, uni_df = opt.predict_students(
                scores_file=scores_file,
                course_file=course_file,
                major_name=major_name,
                out_path=out_file,
                model_dir=r"${modelDir}",
                with_uniform_inverse=1,
                min_grade=60,
                max_grade=90
            )
            
            per_major_files[major_name] = out_file
            total_students += len(pred_df)
            print(f"âœ“ {major_name} å®Œæˆ ({len(pred_df)} åå­¦ç”Ÿ)")
            
        except Exception as e:
            print(f"âœ— {major_name} å¤„ç†å¤±è´¥: {e}")
            continue
    
    # ç”Ÿæˆæ±‡æ€»æ–‡ä»¶
    if per_major_files:
        print("\\næ­£åœ¨ç”Ÿæˆæ±‡æ€»æ–‡ä»¶...")
        frames = []
        for major_name, file_path in per_major_files.items():
            try:
                df = pd.read_excel(file_path, sheet_name="Predictions")
                df['Major'] = major_name
                frames.append(df)
            except Exception as e:
                print(f"âœ— è¯»å– {major_name} ç»“æœå¤±è´¥: {e}")
                continue
        
        if frames:
            total_df = pd.concat(frames, ignore_index=True)
            summary_file = os.path.join(temp_dir, f"${fileInfo.id}_Cohort{year}_Predictions_All.xlsx")
            total_df.to_excel(summary_file, index=False)
            print(f"âœ“ æ±‡æ€»æ–‡ä»¶ç”Ÿæˆå®Œæˆ")
    
    print(f"\\n=== ğŸ‰ æ–‡ä»¶ ${fileInfo.filename} é¢„æµ‹å®Œæˆ ===")
    print(f"âœ“ å¤„ç†å­¦ç”Ÿ: {total_students} äºº")
    print(f"âœ“ ç”Ÿæˆæ–‡ä»¶: {len(per_major_files) + (1 if per_major_files else 0)} ä¸ª")

if __name__ == "__main__":
    main()
`
    
    // å†™å…¥ä¸´æ—¶Pythonè„šæœ¬
    const scriptPath = join(fileInfo.tempDir, `run_prediction_${fileInfo.id}.py`)
    require('fs').writeFileSync(scriptPath, pythonScript)
    
    let output = ''
    let errorOutput = ''
    
    const pythonProcess = spawn('python', [scriptPath], {
      cwd: functionDir,
      env: { 
        ...process.env, 
        PYTHONIOENCODING: 'utf-8',
        PYTHONPATH: functionDir 
      }
    })
    
    pythonProcess.stdout.on('data', (data) => {
      const text = data.toString()
      output += text
      console.log(`Python [${fileInfo.id}]:`, text)
    })
    
    pythonProcess.stderr.on('data', (data) => {
      const text = data.toString()
      errorOutput += text
      console.error(`Python Error [${fileInfo.id}]:`, text)
    })
    
    // è®¾ç½®20åˆ†é’Ÿè¶…æ—¶
    const timeout = setTimeout(() => {
      console.log(`âš ï¸ æ–‡ä»¶ ${fileInfo.filename} å¤„ç†è¶…æ—¶`)
      pythonProcess.kill('SIGTERM')
      
      setTimeout(() => {
        pythonProcess.kill('SIGKILL')
      }, 5000)
      
      resolve({
        success: false,
        output: output,
        error: 'å¤„ç†è¶…æ—¶ (20åˆ†é’Ÿ)',
        outputFiles: []
      })
    }, 20 * 60 * 1000) // 20åˆ†é’Ÿ

    pythonProcess.on('close', async (code) => {
      clearTimeout(timeout)
      
      try {
        // æŸ¥æ‰¾ç”Ÿæˆçš„è¾“å‡ºæ–‡ä»¶
        const files = await readdir(fileInfo.tempDir)
        const outputFiles = files.filter(file => 
          file.startsWith(fileInfo.id) && file.endsWith('.xlsx') && file.includes('Predictions')
        )
        
        resolve({
          success: code === 0 && outputFiles.length > 0,
          output: output,
          error: code !== 0 ? errorOutput : undefined,
          outputFiles: outputFiles
        })
      } catch (error) {
        resolve({
          success: false,
          output: output,
          error: `æ— æ³•è¯»å–è¾“å‡ºç›®å½•: ${error}`,
          outputFiles: []
        })
      }
    })
    
    pythonProcess.on('error', (error) => {
      clearTimeout(timeout)
      resolve({
        success: false,
        output: output,
        error: `æ— æ³•å¯åŠ¨Pythonè¿›ç¨‹: ${error.message}`,
        outputFiles: []
      })
    })
  })
}

export async function POST(request: NextRequest) {
  try {
    const formData = await request.formData()
    const files = formData.getAll('files') as File[]
    const years = formData.getAll('years') as string[]
    const maxConcurrent = parseInt(formData.get('maxConcurrent') as string) || 2
    
    if (!files || files.length === 0) {
      return NextResponse.json({ error: 'è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªæ–‡ä»¶' }, { status: 400 })
    }
    
    if (files.length !== years.length) {
      return NextResponse.json({ error: 'æ–‡ä»¶æ•°é‡ä¸å¹´çº§æ•°é‡ä¸åŒ¹é…' }, { status: 400 })
    }
    
    // éªŒè¯å¹´çº§
    for (const year of years) {
      if (!year || !YEAR_CONFIGS[year]) {
        return NextResponse.json({ error: `æ— æ•ˆçš„å¹´çº§: ${year}` }, { status: 400 })
      }
    }
    
    // éªŒè¯æ–‡ä»¶ç±»å‹
    const allowedTypes = ['.xlsx', '.xls']
    for (const file of files) {
      const fileExtension = extname(file.name).toLowerCase()
      if (!allowedTypes.includes(fileExtension)) {
        return NextResponse.json({ 
          error: `ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: ${file.name}` 
        }, { status: 400 })
      }
    }
    
    const batchId = `batch_${Date.now()}`
    // å…¼å®¹Vercel serverlessç¯å¢ƒ
    const baseDir = process.env.VERCEL || process.env.AWS_LAMBDA_FUNCTION_NAME 
      ? '/tmp' 
      : process.cwd()
    const batchTempDir = join(baseDir, 'temp_predictions', batchId)
    if (!existsSync(batchTempDir)) {
      mkdirSync(batchTempDir, { recursive: true })
    }
    
    console.log(`å¼€å§‹æ‰¹é‡å¤„ç†ï¼Œæ‰¹æ¬¡ID: ${batchId}`)
    console.log(`æ–‡ä»¶æ•°é‡: ${files.length}ï¼Œæœ€å¤§å¹¶å‘: ${maxConcurrent}`)
    
    // å‡†å¤‡æ–‡ä»¶ä¿¡æ¯
    const batchFiles: BatchFileInfo[] = []
    for (let i = 0; i < files.length; i++) {
      const file = files[i]
      const year = years[i]
      const fileId = `file_${i}_${Date.now()}`
      const fileTempDir = join(batchTempDir, fileId)
      
      if (!existsSync(fileTempDir)) {
        mkdirSync(fileTempDir, { recursive: true })
      }
      
      // ä¿å­˜æ–‡ä»¶
      const bytes = await file.arrayBuffer()
      const buffer = Buffer.from(bytes)
      const filePath = join(fileTempDir, file.name)
      await writeFile(filePath, buffer)
      
      batchFiles.push({
        id: fileId,
        filename: file.name,
        year: year,
        filePath: filePath,
        tempDir: fileTempDir
      })
    }
    
    console.log('æ–‡ä»¶ä¿å­˜å®Œæˆï¼Œå¼€å§‹æ‰¹é‡å¯¼å…¥æˆç»©æ•°æ®...')
    
    // æ­¥éª¤1: æ‰¹é‡å¯¼å…¥æˆç»©æ•°æ®
    let academicImportResult: any = null
    try {
      academicImportResult = await batchImportAcademicResults(batchFiles)
      console.log('âœ… æ‰¹é‡æˆç»©æ•°æ®å¯¼å…¥å®Œæˆ')
    } catch (error) {
      console.error('âŒ æ‰¹é‡æˆç»©æ•°æ®å¯¼å…¥å¤±è´¥:', error)
      // ä¸é˜»æ­¢é¢„æµ‹ç»§ç»­è¿›è¡Œ
    }
    
    console.log('å¼€å§‹å¹¶è¡Œå¤„ç†æ–‡ä»¶...')
    
    // æ­¥éª¤2: å¹¶è¡Œå¤„ç†é¢„æµ‹
    const results: { [fileId: string]: any } = {}
    const errors: { [fileId: string]: string } = {}
    const processPromises: Promise<void>[] = []
    
    // æ§åˆ¶å¹¶å‘æ•°é‡
    let currentIndex = 0
    const activeProcesses = new Set<string>()
    
    const processNext = async (): Promise<void> => {
      if (currentIndex >= batchFiles.length) {
        return
      }
      
      const fileInfo = batchFiles[currentIndex++]
      activeProcesses.add(fileInfo.id)
      
      try {
        console.log(`å¼€å§‹å¤„ç†æ–‡ä»¶ ${fileInfo.filename} (å¹¶å‘æ•°: ${activeProcesses.size})`)
        const result = await runSinglePrediction(fileInfo)
        
        if (result.success) {
          results[fileInfo.id] = result
          console.log(`âœ… æ–‡ä»¶ ${fileInfo.filename} å¤„ç†æˆåŠŸ`)
        } else {
          errors[fileInfo.id] = result.error || 'å¤„ç†å¤±è´¥'
          console.log(`âŒ æ–‡ä»¶ ${fileInfo.filename} å¤„ç†å¤±è´¥: ${result.error}`)
        }
      } catch (error) {
        errors[fileInfo.id] = error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'
        console.log(`âŒ æ–‡ä»¶ ${fileInfo.filename} å¤„ç†å¼‚å¸¸:`, error)
      } finally {
        activeProcesses.delete(fileInfo.id)
        
        // ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªæ–‡ä»¶
        if (currentIndex < batchFiles.length) {
          await processNext()
        }
      }
    }
    
    // å¯åŠ¨åˆå§‹å¹¶å‘å¤„ç†
    for (let i = 0; i < Math.min(maxConcurrent, batchFiles.length); i++) {
      processPromises.push(processNext())
    }
    
    // ç­‰å¾…æ‰€æœ‰å¤„ç†å®Œæˆ
    await Promise.all(processPromises)
    
    console.log('æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆ')
    
    // ç»Ÿè®¡ç»“æœ
    const totalFiles = batchFiles.length
    const successfulFiles = Object.keys(results).length
    const failedFiles = Object.keys(errors).length
    
    // æ”¶é›†æ‰€æœ‰è¾“å‡ºæ–‡ä»¶
    const allOutputFiles: string[] = []
    Object.values(results).forEach((result: any) => {
      if (result.outputFiles) {
        allOutputFiles.push(...result.outputFiles)
      }
    })
    
    const batchResult: BatchPredictionResult = {
      batchId,
      totalFiles,
      results,
      errors,
      startTime: Date.now(),
      endTime: Date.now()
    }
    
    console.log(`ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆ - æˆåŠŸ: ${successfulFiles}, å¤±è´¥: ${failedFiles}`)
    
    return NextResponse.json({
      success: true,
      message: `æ‰¹é‡å¤„ç†å®Œæˆ: ${successfulFiles}/${totalFiles} ä¸ªæ–‡ä»¶æˆåŠŸå¤„ç†`,
      batchResult,
      academicImportResult,
      summary: {
        totalFiles,
        successfulFiles,
        failedFiles,
        allOutputFiles
      }
    })
    
  } catch (error) {
    console.error('æ‰¹é‡å¤„ç†APIé”™è¯¯:', error)
    return NextResponse.json({
      success: false,
      error: 'æ‰¹é‡å¤„ç†å¤±è´¥',
      details: error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'
    }, { status: 500 })
  }
}

