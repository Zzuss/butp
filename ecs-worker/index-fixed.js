const { createClient } = require('@supabase/supabase-js')
const XLSX = require('xlsx')
const fs = require('fs')
const path = require('path')
const axios = require('axios')
const winston = require('winston')
const cron = require('node-cron')
require('dotenv').config()

// é…ç½®æ—¥å¿—
const logger = winston.createLogger({
  level: 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.json()
  ),
  transports: [
    new winston.transports.File({ filename: 'logs/error.log', level: 'error' }),
    new winston.transports.File({ filename: 'logs/combined.log' }),
    new winston.transports.Console({
      format: winston.format.simple()
    })
  ]
})

// Supabaseé…ç½®
const supabaseUrl = process.env.SUPABASE_URL
const supabaseKey = process.env.SUPABASE_SERVICE_ROLE_KEY
const supabase = createClient(supabaseUrl, supabaseKey)

// é…ç½®
const BATCH_SIZE = parseInt(process.env.BATCH_SIZE) || 1000
const TEMP_DIR = path.join(__dirname, process.env.TEMP_DIR || 'temp')
const MAX_CONCURRENT_TASKS = parseInt(process.env.MAX_CONCURRENT_TASKS) || 2

// ç¡®ä¿ä¸´æ—¶ç›®å½•å­˜åœ¨
if (!fs.existsSync(TEMP_DIR)) {
  fs.mkdirSync(TEMP_DIR, { recursive: true })
}

if (!fs.existsSync('logs')) {
  fs.mkdirSync('logs', { recursive: true })
}

class ImportWorker {
  constructor() {
    this.isProcessing = false
    this.currentTasks = new Set()
  }

  // å¯åŠ¨å·¥ä½œè¿›ç¨‹
  async start() {
    logger.info('ğŸš€ ECSå¯¼å…¥å·¥ä½œè¿›ç¨‹å¯åŠ¨')
    
    // ç«‹å³æ£€æŸ¥ä¸€æ¬¡
    await this.processQueue()
    
    // æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡é˜Ÿåˆ—
    cron.schedule('*/30 * * * * *', async () => {
      if (!this.isProcessing && this.currentTasks.size < MAX_CONCURRENT_TASKS) {
        await this.processQueue()
      }
    })

    // æ¯å°æ—¶æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    cron.schedule('0 * * * *', async () => {
      await this.cleanupTempFiles()
    })

    logger.info('âœ… å®šæ—¶ä»»åŠ¡å·²å¯åŠ¨')
  }

  // å¤„ç†é˜Ÿåˆ—
  async processQueue() {
    if (this.isProcessing) {
      return
    }

    try {
      this.isProcessing = true
      
      // æŸ¥æ‰¾å¾…å¤„ç†çš„ä»»åŠ¡
      const { data: tasks, error } = await supabase
        .from('import_tasks')
        .select('*')
        .eq('status', 'pending')
        .order('created_at', { ascending: true })
        .limit(MAX_CONCURRENT_TASKS - this.currentTasks.size)

      if (error) {
        throw error
      }

      if (!tasks || tasks.length === 0) {
        return
      }

      logger.info(`ğŸ“‹ æ‰¾åˆ° ${tasks.length} ä¸ªå¾…å¤„ç†ä»»åŠ¡`)

      // å¹¶å‘å¤„ç†ä»»åŠ¡
      const promises = tasks.map(task => this.processTask(task))
      await Promise.all(promises)

    } catch (error) {
      logger.error('å¤„ç†é˜Ÿåˆ—å¤±è´¥:', error)
    } finally {
      this.isProcessing = false
    }
  }

  // å¤„ç†å•ä¸ªä»»åŠ¡
  async processTask(task) {
    const taskId = task.id
    this.currentTasks.add(taskId)

    try {
      logger.info(`ğŸ”„ å¼€å§‹å¤„ç†ä»»åŠ¡: ${taskId}`)

      // æ ‡è®°ä»»åŠ¡ä¸ºå¤„ç†ä¸­
      await supabase
        .from('import_tasks')
        .update({ status: 'processing' })
        .eq('id', taskId)

      // æ¸…ç©ºå½±å­è¡¨
      await this.clearShadowTable()

      // è·å–ä»»åŠ¡çš„æ–‡ä»¶åˆ—è¡¨
      const { data: files, error: filesError } = await supabase
        .from('import_file_details')
        .select('*')
        .eq('task_id', taskId)
        .eq('status', 'pending')

      if (filesError) {
        throw filesError
      }

      if (!files || files.length === 0) {
        throw new Error('æ²¡æœ‰æ‰¾åˆ°å¾…å¤„ç†çš„æ–‡ä»¶')
      }

      let totalRecords = 0
      let importedRecords = 0
      let hasErrors = false

      // å¤„ç†æ¯ä¸ªæ–‡ä»¶
      for (const file of files) {
        try {
          const result = await this.processFile(file)
          totalRecords += result.totalRecords
          importedRecords += result.importedRecords
        } catch (fileError) {
          logger.error(`å¤„ç†æ–‡ä»¶å¤±è´¥: ${file.file_name}`, fileError)
          hasErrors = true
          
          // æ ‡è®°æ–‡ä»¶å¤„ç†å¤±è´¥
          await supabase
            .from('import_file_details')
            .update({
              status: 'failed',
              error_message: fileError.message
            })
            .eq('id', file.id)
        }
      }

      // å®Œæˆä»»åŠ¡
      if (hasErrors || importedRecords === 0) {
        await this.failTask(taskId, totalRecords, importedRecords, 'éƒ¨åˆ†æ–‡ä»¶å¤„ç†å¤±è´¥')
      } else {
        await this.completeTask(taskId, totalRecords, importedRecords)
      }

    } catch (error) {
      logger.error(`ä»»åŠ¡å¤„ç†å¤±è´¥: ${taskId}`, error)
      await this.failTask(taskId, 0, 0, error.message)
    } finally {
      this.currentTasks.delete(taskId)
    }
  }

  // å¤„ç†å•ä¸ªæ–‡ä»¶
  async processFile(fileDetail) {
    logger.info(`ğŸ“„ å¤„ç†æ–‡ä»¶: ${fileDetail.file_name}`)

    // æ ‡è®°æ–‡ä»¶ä¸ºå¤„ç†ä¸­
    await supabase
      .from('import_file_details')
      .update({ 
        status: 'processing',
        processed_at: new Date().toISOString()
      })
      .eq('id', fileDetail.id)

    // ä¸‹è½½æ–‡ä»¶
    const filePath = await this.downloadFile(fileDetail)
    
    // è¯»å–Excelæ–‡ä»¶
    const workbook = XLSX.readFile(filePath)
    const sheetName = workbook.SheetNames[0]
    const worksheet = workbook.Sheets[sheetName]
    const jsonData = XLSX.utils.sheet_to_json(worksheet)

    if (jsonData.length === 0) {
      throw new Error('æ–‡ä»¶ä¸­æ²¡æœ‰æ•°æ®')
    }

    // å¤„ç†æ•°æ®
    const processedData = jsonData.map(row => this.mapExcelRow(row))
    
    // åˆ†æ‰¹å¯¼å…¥
    let importedCount = 0
    for (let i = 0; i < processedData.length; i += BATCH_SIZE) {
      const batch = processedData.slice(i, i + BATCH_SIZE)
      
      const { error } = await supabase
        .from('academic_results_old')
        .insert(batch)

      if (error) {
        throw new Error(`æ‰¹æ¬¡å¯¼å…¥å¤±è´¥: ${error.message}`)
      }

      importedCount += batch.length
      logger.info(`âœ… æ‰¹æ¬¡å¯¼å…¥æˆåŠŸ: ${importedCount}/${processedData.length}`)
    }

    // æ›´æ–°æ–‡ä»¶çŠ¶æ€
    await supabase
      .from('import_file_details')
      .update({
        status: 'completed',
        records_count: jsonData.length,
        imported_count: importedCount
      })
      .eq('id', fileDetail.id)

    // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    if (fs.existsSync(filePath)) {
      fs.unlinkSync(filePath)
    }

    return {
      totalRecords: jsonData.length,
      importedRecords: importedCount
    }
  }

  // ä¸‹è½½æ–‡ä»¶ï¼ˆæ™ºèƒ½é€‰æ‹©æœ¬åœ°æˆ–çº¿ä¸Šï¼‰
  async downloadFile(fileDetail) {
    const fileName = `${fileDetail.file_id}.xlsx`
    const filePath = path.join(TEMP_DIR, fileName)
    
    // å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œç›´æ¥è¿”å›
    if (fs.existsSync(filePath)) {
      logger.info(`æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½: ${fileName}`)
      return filePath
    }
    
    // ä»ç¯å¢ƒå˜é‡è·å–ä¸‹è½½æºï¼Œæˆ–ä½¿ç”¨é»˜è®¤å€¼
    const downloadSources = process.env.DOWNLOAD_SOURCES 
      ? process.env.DOWNLOAD_SOURCES.split(',')
      : ['https://butp.tech', 'http://localhost:3000', 'http://127.0.0.1:3000']
    
    const downloadUrls = downloadSources.map(source => 
      `${source.trim()}/api/admin/grades-import/download/${fileDetail.file_id}`
    )
    
    for (let i = 0; i < downloadUrls.length; i++) {
      const downloadUrl = downloadUrls[i]
      try {
        logger.info(`ğŸ“¥ å°è¯•ä»æº ${i + 1} ä¸‹è½½æ–‡ä»¶: ${downloadUrl}`)
        
        const response = await axios({
          method: 'GET',
          url: downloadUrl,
          responseType: 'stream',
          timeout: 15000, // 15ç§’è¶…æ—¶ï¼Œå› ä¸ºè¦å°è¯•å¤šä¸ªæº
          headers: {
            'User-Agent': 'ECS-Worker/1.0'
          }
        })
        
        const writer = fs.createWriteStream(filePath)
        response.data.pipe(writer)
        
        return new Promise((resolve, reject) => {
          writer.on('finish', () => {
            logger.info(`âœ… æ–‡ä»¶ä¸‹è½½å®Œæˆ: ${fileName} (æº: ${i + 1})`)
            resolve(filePath)
          })
          writer.on('error', (error) => {
            logger.error(`âŒ æ–‡ä»¶å†™å…¥å¤±è´¥: ${fileName}`, error)
            reject(error)
          })
          
          // è®¾ç½®è¶…æ—¶
          setTimeout(() => {
            writer.destroy()
            reject(new Error('ä¸‹è½½è¶…æ—¶'))
          }, 20000)
        })
        
      } catch (error) {
        logger.warn(`âš ï¸ æº ${i + 1} ä¸‹è½½å¤±è´¥: ${error.message}`)
        
        // å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªæºï¼Œç»§ç»­å°è¯•ä¸‹ä¸€ä¸ª
        if (i < downloadUrls.length - 1) {
          continue
        }
        
        // æ‰€æœ‰æºéƒ½å¤±è´¥äº†
        logger.error(`âŒ æ‰€æœ‰ä¸‹è½½æºéƒ½å¤±è´¥: ${fileName}`)
        throw new Error(`æ–‡ä»¶ä¸‹è½½å¤±è´¥: å°è¯•äº† ${downloadUrls.length} ä¸ªæºï¼Œéƒ½æ— æ³•ä¸‹è½½`)
      }
    }
  }

  // æ•°æ®æ˜ å°„
  mapExcelRow(row) {
    return {
      SNH: row.SNH || null,
      Name: row.Name || null,
      Course_Name: row.Course_Name || null,
      Course_Code: row.Course_Code || null,
      Credit: row.Credit ? parseFloat(row.Credit) : null,
      Grade: row.Grade || null,
      Score: row.Score ? parseFloat(row.Score) : null,
      GPA: row.GPA ? parseFloat(row.GPA) : null,
      Semester: row.Semester || null,
      Exam_Type: row.Exam_Type || null,
      Assessment_Method: row['Assessment_Method '] || row.Assessment_Method || null,
      year: row.year ? parseInt(row.year) : null,
    }
  }

  // æ¸…ç©ºå½±å­è¡¨
  async clearShadowTable() {
    logger.info('ğŸ§¹ æ¸…ç©ºå½±å­è¡¨')
    try {
      const { error } = await supabase.rpc('truncate_results_old')
      if (error) {
        throw error
      }
    } catch (error) {
      // å¦‚æœRPCå¤±è´¥ï¼Œä½¿ç”¨DELETE
      const { error: deleteError } = await supabase
        .from('academic_results_old')
        .delete()
        .neq('SNH', 'dummy_value_that_should_not_exist')
      
      if (deleteError) {
        throw deleteError
      }
    }
  }

  // å®Œæˆä»»åŠ¡
  async completeTask(taskId, totalRecords, importedRecords) {
    logger.info(`ğŸ‰ ä»»åŠ¡å®Œæˆ: ${taskId}`)
    
    // æ‰§è¡ŒåŸå­äº¤æ¢
    const { error: swapError } = await supabase.rpc('swap_results_with_old')
    if (swapError) {
      throw new Error(`åŸå­äº¤æ¢å¤±è´¥: ${swapError.message}`)
    }

    // æ›´æ–°ä»»åŠ¡çŠ¶æ€
    await supabase
      .from('import_tasks')
      .update({
        status: 'completed',
        total_records: totalRecords,
        imported_records: importedRecords,
        completed_at: new Date().toISOString()
      })
      .eq('id', taskId)
  }

  // ä»»åŠ¡å¤±è´¥
  async failTask(taskId, totalRecords, importedRecords, errorMessage) {
    logger.error(`âŒ ä»»åŠ¡å¤±è´¥: ${taskId} - ${errorMessage}`)
    
    // æ¸…ç©ºå½±å­è¡¨ä½œä¸ºå›æ»š
    await this.clearShadowTable()

    // æ›´æ–°ä»»åŠ¡çŠ¶æ€
    await supabase
      .from('import_tasks')
      .update({
        status: 'failed',
        total_records: totalRecords,
        imported_records: importedRecords,
        error_message: errorMessage,
        completed_at: new Date().toISOString()
      })
      .eq('id', taskId)
  }

  // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
  async cleanupTempFiles() {
    try {
      const files = fs.readdirSync(TEMP_DIR)
      const now = Date.now()
      const maxAge = 24 * 60 * 60 * 1000 // 24å°æ—¶

      for (const file of files) {
        const filePath = path.join(TEMP_DIR, file)
        const stats = fs.statSync(filePath)
        
        if (now - stats.mtime.getTime() > maxAge) {
          fs.unlinkSync(filePath)
          logger.info(`ğŸ—‘ï¸ æ¸…ç†è¿‡æœŸæ–‡ä»¶: ${file}`)
        }
      }
    } catch (error) {
      logger.error('æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥:', error)
    }
  }
}

// å¯åŠ¨å·¥ä½œè¿›ç¨‹
const worker = new ImportWorker()
worker.start().catch(error => {
  logger.error('å¯åŠ¨å·¥ä½œè¿›ç¨‹å¤±è´¥:', error)
  process.exit(1)
})

// ä¼˜é›…å…³é—­
process.on('SIGINT', () => {
  logger.info('ğŸ›‘ æ”¶åˆ°å…³é—­ä¿¡å·ï¼Œæ­£åœ¨ä¼˜é›…å…³é—­...')
  process.exit(0)
})

process.on('SIGTERM', () => {
  logger.info('ğŸ›‘ æ”¶åˆ°ç»ˆæ­¢ä¿¡å·ï¼Œæ­£åœ¨ä¼˜é›…å…³é—­...')
  process.exit(0)
})
